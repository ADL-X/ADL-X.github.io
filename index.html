<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
 

  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LLAVIDAL</title>
  <link rel="icon" type="image/x-icon" href="static/images/llavidal_logo.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <img src="static/images/llavidal.png" style="width: 20%;"/><h1 class="title is-1 publication-title">LLAVIDAL: A <u>L</u>arge <u>LA</u>nguage <u>VI</u>sion Model for <u>D</u>aily <u>A</u>ctivities of <u>L</u>iving
            </h1>
            <div class="is-size-5 publication-authors" style="margin-bottom: 0.25em;">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://dominickrei.github.io/" target="_blank">Dominick Reilly</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="https://chakrabortyrajatsubhra.github.io/" target="_blank" style="margin-left: 0.5cm;">Rajatsubhra Chakraborty</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="https://webpages.charlotte.edu/asinha13/" target="_blank" style="margin-left: 0.5cm;">Arkaprava Sinha</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="https://manishgovind.github.io/" target="_blank" style="margin-left: 0.5cm;">Manish Kumar Govind</a><sup>1</sup>
              </span>

              <br>
              <!-- Dominick Reilly, Rajatsubhra Chakraborty, Arkaprava Sinha, Manish Kumar Govind, Pu Wang, Francois Bremond, Le Xue, Srijan Das -->

              <span class="author-block">
                <a href="https://webpages.charlotte.edu/pwang13/" target="_blank" style="margin-left: 0.5cm;">Pu Wang</a><sup>1</sup>
              </span>
              
              <span class="author-block">
                  <a href="https://www-sop.inria.fr/stars/Francois.Bremond/" target="_blank" style="margin-left: 0.5cm;">Francois Bremond</a><sup>3,4</sup>
              </span>

              <span class="author-block">
                <a href="https://x.com/le_xue01" target="_blank" style="margin-left: 0.6cm;">Le Xue</a><sup>2</sup>
              </span>
              
              <span class="author-block">
                <a href="https://srijandas07.github.io/" target="_blank" style="margin-left: 0.5cm;">Srijan Das</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block" style="margin-left: 0.25cm;"> <sup>1</sup> UNC Charlotte </span>
              <span class="author-block" style="margin-left: 0.25cm;"> <sup>2</sup> Salesforce AI Research </span>
              <span class="author-block" style="margin-left: 0.25cm;"> <sup>3</sup> Inria </span>
              <span class="author-block" style="margin-left: 0.25cm;"> <sup>4</sup> UniversitÃ© CÃ´te d'Azur </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.09390" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/ADL-X/LLAVIDAL" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!--Data Gdrive Link -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/dreilly/ADL-X/tree/main" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span>ðŸ¤— Data</span>
                  </a>
                </span>
              </div>
            </div>

        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video poster="" id="tree" autoplay muted loop height="100%">
        <source src="static/videos/adlxteaser_final.mp4"type="video/mp4">
      </video> -->
      <img src="static/images/web-teaser.jpg" alt="Our paper's teaser image"/>
      <h2 class="subtitle has-text-centered">
        Comparison of LLVM and our proposed LLAVIDAL for understanding Activities of Daily Living. In real world scenarios, web-video trained models struggle to understand the fine-grained details and human-object interactions present in Activities of Daily Living. In contrast, LLAVIDAL is trained on a curated ADL dataset called ADL-X and incorporates specialized modalities (3D human skeleton data and human-object interaction) into its training, enabling more accurate interpretation of daily activities.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Current Large Language Vision Models (LLVMs) trained on web videos perform well in general video understanding but struggle with fine-grained details, complex human-object interactions (HOI), and view-invariant representation learning essential for Activities of Daily Living (ADL). This limitation stems from a lack of specialized ADL video instruction-tuning datasets and insufficient modality integration to capture discriminative action representations. To address this, we propose a semi-automated framework for curating ADL datasets, creating ADL-X, a multiview, multimodal RGBS instruction-tuning dataset. Additionally, we introduce LLAVIDAL, an LLVM integrating videos, 3D skeletons, and HOIs to model ADL's complex spatiotemporal relationships. For training LLAVIDAL a simple joint alignment of all modalities yields suboptimal results; thus, we propose a Multimodal Progressive (MMPro) training strategy, incorporating modalities in stages following a curriculum. We also establish ADL MCQ and video description benchmarks to assess LLVM performance in ADL tasks. Trained on ADL-X, LLAVIDAL achieves state-of-the-art performance across ADL benchmarks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item is-centered">
        <!-- Your image here -->
        <img src="static/images/adlx-curation-web.jpg" alt="data curation image"/>
        <h2 class="subtitle has-text-centered" style="font-size: large;">
          ADL-X Data Curation Process
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/mmpro-web.jpg" alt="mmpro training strategy image" style="width: 50%;"/>
        <h2 class="subtitle has-text-centered">
          MMPro Training Strategy
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/modality-pipeline-web.jpg" alt="modality pipeline image"/>
        <h2 class="subtitle has-text-centered">
          Skeleton and HOI as Features, QA, and Context Pipeline
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<section class="hero is-small">
  
  <div class="container">
    <h2 class="title is-3 has-text-centered">Quantitative Results</h2>
    <div class="results-grid">
      
      <div class="item">
        <img src="static/images/Impact_of_ADL-X_Training.png" alt="Quantitative Result 7">
        <h2 class="subtitle">Impact of ADL-X Training</h2>
      </div>
      <div class="item">
        <img src="static/images/charades_SH.png" alt="Quantitative Result 2">
        <h2 class="subtitle">ADLMCQ - Action Recognition</h2>
      </div>
      <div class="item">
        <img src="static/images/lemma_TSU.png" alt="Quantitative Result 3">
        <h2 class="subtitle">ADLMCQ - Action Forecasting</h2>
      </div>
      <div class="item">
        <img src="static/images/ADLMCQ-AR.png" alt="Quantitative Result 4">
        <h2 class="subtitle">Effect of Introduction of Pose and Object Cues on ADLMCQ Action Recognition</h2>
      </div>
      <div class="item">
        <img src="static/images/ADLMCQ-AF.png" alt="Quantitative Result 5">
        <h2 class="subtitle">Effect of Introduction of Pose and Object Cues on ADLMCQ Action Forecasting</h2>
      </div>
      <div class="item">
        <img src="static/images/AD.png" alt="Quantitative Result 6">
        <h2 class="subtitle">Effect of Introduction of Pose and Object Cues on ADLMCQ Action Description</h2>
      </div>
      
    </div>
  </div>
</section>


<section class="hero is-small">
  
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Qualitative Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/VD.png" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
          Video Description
          </h2>
        </div>
       <div class="item">
        <!-- Your image here -->

        <img src="static/images/AR.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Action Recognition
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/AF.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        Action Forecasting
        </h2>
      </div>
  </div>
</div>
</div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title has-text-centered">BibTeX</h2>
      <pre><code>
        @article{llavidal2024,
          title={LLAVIDAL: A Large LAnguage VIsion Model for Daily Activities of Living}, 
          author={Dominick Reilly and Rajatsubhra Chakraborty and Arkaprava Sinha and Manish Kumar Govind and Pu Wang and Francois Bremond and Le Xue and Srijan Das},
          journal={arXiv},
          year={2024},
          volume={2406.09390}
        } 
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!--License citation-->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title has-text-centered">Usage License</h2>
    <p>The dataset is protected under the CC-BY license of Creative Commons, which allows users to distribute, remix, adapt, and build upon the material in any medium or format, as long as the creator is attributed. The license allows ADL-X for commercial use. As the authors of this manuscript and collectors of this dataset, we reserve the right to distribute the data.</p>
  </div>
</section>
<!--End License-->




  <footer class="footer">
  
    <div class="container is-max-desktop content">
          <h2 class="title has-text-centered">Acknowledgement</h2>
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template
            </a>.
          </p>

  
  </div>
</footer>
  </body>
  </html>
